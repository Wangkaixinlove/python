## python菜鸟之路(仅此记录研究生学习之路，不断更新)  
#### 第一天 下载之路 2019.7.11  
start  
1.下载home-brew,目的是为了更新python，自带2.7.0版本，最好实现2.版本与3.版本共存  
2.使用brew搜索并下载python3版本  
3.使用百度网盘下载pycharm专业免费版 有效期到2100年 百度网盘好慢 恨不得分分钟开一个vip  
4.创建第一个python程序并输出“hello world!”  
参考的博客：[链接](https://www.jianshu.com/p/79f5eae9f04f)  
end. 
#### 第二天 读论文ing... 2019.7.12  
start   
1.读了两篇paper 一篇是关于情感分析的 一篇是关于知识图谱的。   
2.情感分析属于自然语言处理的一部分。  
3.知识图谱主要和数据结合在一起，跟数据关系息息相关,应用场景表广阔：可以进行辅助搜索、辅助问答、辅助决策、辅助AI等等。  
4.继续学习python:学习了:如何使用变量;如何创建描述性变量名以及如何消除名称错误和语法错误;字符串是什么，以及如何使用小写、大写和首字母大写方式显示字符串;使用空白来显示整洁的输出，以及如何剔除字符串中多余的空白;如何使用整数和浮点数;使用数值数据时需要注意的意外行为。如何编写说明性注释，让代码对其他人来说更容易理解。  
end  
#### 2019.7.13-2019.7.15  
start  
这两天一直没更新，但是不是没有学习哦，把python基础基本上学完了  
学习了：  
1.列表是什么以及如何使用其中的元素;如何定义列表以及如何增删元素;如何对列表进行永久性排序，以及如何为展示列表而进行临时排序;如何确定列
表的长度，以及在使用列表时如何避免索引错误。  
2.如何高效地处理列表中的元素;如何使用for 循环遍历列表，Python如何根据缩进来确定程序的结构以及如何避免一些常见的缩进错误;如何创建简单的 数字列表，以及可对数字列表执行的一些操作;如何通过切片来使用列表的一部分和复制列表。还学习了元组(它对不应变化的值提供了一定程度的保护)，以及在代码变得 越来越复杂时如何设置格式，使其易于阅读。  
3.如何编写结果要么为Ture 要么为False 的条件测试。学习了如何编写简单的if 语句、if-else 语句和if-elif-else 结构。  
4.如何定义字典，以及如何使用存储在字典中的信息;如何访问和修改字典中的元素，以及如何遍历字典中的所有信息;如何遍历字典中所有的键-值对、所
有的键和所有的值;如何在列表中嵌套字典、在字典中嵌套列表以及在字典中嵌套字典。  
5.如何在程序中使用input() 来让用户提供信息;如何处理文本和数字输入，以及如何使用while 循环让程序按用户的要求不断地运行;多种控制while 循环流程的方式:设置活动标志、使用break 语句以及使用continue 语句;如何使用while 循环在列表之间移动元素，以及如何从列表中删除所有包含特定值的元素;如何 结合使用while 循环和字典。  
6.如何编写函数，以及如何传递实参，让函数能够访问完成其工作所需的信息;如何使用位置实参和关键字实参，以及如何接受任意数量的实参;显示输出 的函数和返回值的函数;如何将函数同列表、字典、if 语句和while 循环结合起来使用。模块以及如何引入模块。  
7.如何编写类;如何使用属性在类中存储信息，以及如何编写方法，以让类具备所需的行为;如何编写方法__init__() ，以便根据类创建包含所需属性的 实例。见识了如何修改实例的属性——包括直接修改以及通过方法进行修改。还了解了:使用继承可简化相关类的创建工作;将一个类的实例用作另一个类的属性可让类更 简洁。  
8.如何使用文件;如何一次性读取整个文件，以及如何以每次一行的方式读取文件的内容;如何写入文件，以及如何将文本附加到文件末尾;什么是异常以 及如何处理程序可能引发的异常;如何存储Python数据结构，以保存用户提供的信息，避免用户每次运行程序时都需要重新提供。  
9.如何使用模块unittest 中的工具来为函数和类编写测试;如何编写继承unittest.TestCase 的类，以及如何编写测试方法，以核实函数和类的行为符合预期;如何使用方法setUp() 来根据类高效地创建实例并设置其属性，以便在类的所有测试方法中都可使用它们。  
参考书籍 《Python编程：从入门到实践》  
end  
#### 2019.7.16-2019.7.17  
start   
1.阅读与知识图谱相关的博客 链接：https://blog.csdn.net/pelhans/article/category/7607589  
2.整理有关知识图谱思维导图 链接：https://www.processon.com/view/link/5d2ee024e4b02015bd805eed  
3.下载知识图谱相关的视频及资料  
4.开始学习知识图谱第一讲  
end  
#### 2019.7.18-2019.7.19
start  
1.学习知识图谱第一讲：  
知识图谱的概述 KG的本质 常用知识库 知识表示、知识抽取、知识存储、知识融合等概念  
2.学习知识图谱第二讲：  
早期知识表示方法、基于语义网的知识表示框架，其中最重要的是RDF，SPARQL查询以及查询实例  
3.下载protege  
完成构建类、子类、类之间的关系、对象属性、建立数据属性、建立实例、添加实例之间的关系等练习  
end. 
#### 2019.7.20-2019.7.21  
start  
1.学习知识图谱第三讲：  
主要讲了知识抽取中的关系抽取及事件抽取，事件抽取也可理解为多元关系抽取。实体识别与分类，以及关系抽取的步骤。  
2.学习知识图谱第四讲：  
学习了斯坦福大学基于deepdive知识抽取(三元组)的实例，资源地址：http://www.openkg.cn/ dataset/cn-deepdive  
3.下载scrapy爬虫框架：  
使用pip安装,需要先下载Twisted插件，根据参考博客：https://blog.csdn.net/qq_41646358/article/details/81335359  
Scrapy数据处理流程:  
当需要打开一个域名时,爬虫开始获取第一个url,并返回给引擎；   
引擎把url作为一个请求交给调度器；  
引擎再次对调度器发出请求,并接收上一次让调度器处理的请求；  
引擎将请求交给下载器；  
下载器下载完成后,作为响应返回给引擎；  
引擎把响应交给爬虫,爬虫开始进一步处理,处理完成后有两个数据,一个是需要跟进的url,另一个是获取到的item数据,然后把结果返回给引擎；  
引擎把需要跟进的url给调度器,把获取的item数据给管道；  
然后从第2步开始循环,知道获取信息完毕。只有调度器中没有任何请求时,程序才会停止；  
end.
#### 2019.7.22-1019.7.24
start  
1.学习知识图谱第五讲：知识存储  
2.下载MySQL及可视化工具navicat for mysql  
3.进行一个实战：将百度贴吧的数据爬虫并存储到关系型数据库MySQL中，将数据结构化，记录过程到CSDN个人博客：https://blog.csdn.net/qq_36812990/article/details/97125764  
end.
#### 2019.7.25-2019.8.2
start  
进行实战：基于知识图谱构建电影知识问答系统  
构建过程参考：https://blog.csdn.net/qq_36812990/article/details/97619345  
系统最终可以回答：  
1. 某演员演了什么电影
2. 某电影有哪些演员出演
3. 演员A和演员B合作出演了哪些电影
4. 某演员参演的评分大于X的电影有哪些
5. 某演员出演过哪些类型的电影
6. 某演员出演的XX类型电影有哪些。
7. 某演员出演了多少部电影。
8. 某演员是喜剧演员吗。
9. 某演员的生日/出生地/英文名/简介
10. 某电影的简介/上映日期/评分
等问题。  
end
#### 2019.8.3-2019.8.5
start  
阅读论文  
阅读有关知识图谱综述、发展过程的论文  
阅读有关实体抽取，以及HMM、CRF原理论文   
阅读报告地址：https://blog.csdn.net/qq_36812990/article/details/98340330  
进行Django实践，最终想实现将之前的电影知识问答系统可视化，增强交互性。  
end  
#### 2019.8.6-2019.8.8  
start  
学习语料预处理过程    
学习使用jieba工具，掌握分词、词性标注、自定义词典、关键字提取等。      
将学习记录在博客中，链接：https://blog.csdn.net/qq_36812990/article/details/98613483  
end    
#### 2019.8.9-2019.8.11  
start  
jieba中的关键字提取基于TextRank 算法，读了一篇官网提供的论文。  
论文主要的思想是基于图模型对词句进行排序，生成关键词和摘要，从PageRank算法引入，他的算法核心主要是：如果一个网页被很多其他网页链接到，说明这个网页比较重要，即该网页的PR值（PageRank值）会相对较高；如果一个PR值很高的网页链接到一个其他网页，那么被链接到的网页的PR值会相应地因此而提高。每个链接相当于图的一个顶点，并给出了PR值的计算公式。接着讲了随机浏览模型，随机浏览的方式更符合用户的真实浏览行为，人们浏览网页到达一定的时间点开始随机查看。而TextRank算法是由PageRank算法改进而来的，二者的思想有相同之处，区别在于：PageRank算法根据网页之间的链接关系构造网络，而TextRank算法根据词之间的共现关系构造网络；PageRank算法构造的网络中的边是有向无权边，而TextRank算法构造的网络中的边是无向有权边。论文中详细介绍了该算法在关键字提取和在提取摘要中的应用以及评价试验的结果。  
end   
#### 2019.8.12-2019.8.14  
start  
查看周志华《机器学习》一书中对概率图模型的介绍，并记录在博客中，链接：https://blog.csdn.net/qq_36812990/article/details/99199745  
阅读《基于层叠条件随机场模型的中文机构名自动识别》论文  
主要针对于多嵌套机构名，对各粗分词串先在低层进行人名与地名的识别，将识别结果传到高层模型，为高层机构名条件随机场模型对复杂机构名的识别提供决策支持，最后采用约束的前向后向算法对识别的结果进行可信度计算。  
end  
#### 2019.8.15-2019.8.18  
start  
学习周志华《机器学习》第二章和第三章：模型评估与选择，其中包括经验误差与过拟合、评估方法、调参和最终模型等。  
学习笔记记录在博客中：https://mp.csdn.net/postedit/99704079  
开始做基于 CRF 的中文命名实体识别模型实现的实验  
实验过程正在整理成博客  
end  
#### 2019.8.22  
start  
基于chatbot的自动问答  
使用pip install chatterbot安装库  
报错未解决 后来解决方案是去github下载源码 使用setup.py进行安装 在文件内部仍报错无法运行  
查看源码需要配置的环境 使用pip list对照版本 发现pyyaml版本太低 进行更新  更新时继续报错 使用命令行语句忽视已安装的pyyaml后 成功安装  
sqlalechemy也进行更新 使用命令pip install --upgrade sqlalechemy即可  
end   
#### 2019.8.23-8.26
start  
实现自动问答机器人，整理基于chatbot的自动问答的实验过程  
写博客《基于chatterbot制作聊天机器人》  
博客链接：https://blog.csdn.net/qq_36812990/article/details/100034746  
阅读学习《统计学习方法》一书中的条件随机场及隐马尔可夫模型  
end  
#### 2019.8.27-2019.9.2 
start  
整理暑期所学知识  
制作学习汇报PPT  
end  
#### 2019.9.9  
start  
汇报内容：论文总结  
1.论文名称：《基于微博文本的细致情绪分析研究》  
2.提出问题：在现有的基于情感词典的研究中，仍有大量没有录入情感词典的新词；传统机器学习的情感分析挖掘出的情感特征不全面；人工特征提取耗费大量时间。  
3.解决方法：针对情感词典不全面，基于SOPMI算法构建了一个拓充情感词典，设计了一种将情感次与特定的寓意规则相结合的权重算法；针对传统机器学习情感分析的情感特征不全面，在特征的选取与组合、维度的设定与分类算法三个方面进行实验，获得最佳分类器；针对特征提取耗费时间，提出了运用Word2vec模型生成词向量结合深度学习混合模型LChybrid来训练数据，提取向量中的情感信息以完成情感细致极性分类。  
4.数据集：python爬虫收集44857条微博语料  
5.创新之处：首先在词典方面，扩充情感词典，提升覆盖度对提高细致分类准确性具有重要意义。其次在特征选择方面设计了三种情感特征选择方式，通过实验对比五种机器学习算法得出最优的分类器LinearSVC。本文最重要的核心思想是提出了LChybird模型，即LSTM-CNN混合模型。将利用微博文本生成的词向量输入到CNN卷积层获得词向量的特征，进入池化层降低特征的维度，经若干次卷积和池化处理后进入LSTM学习情感信息，经过全连接层利用softmax得倒类别分布向量，完成分类。
通过阅读此篇论文，对情感分析概括的技术、实验方法、实验模型有了更深入的理解，数据集及数据的预处理十分重要，也是实验中最耗费时间的一部分，实验时要对不同的学习模型选择准则进行评价，最终实现求解最优模型。  
####  2019.9.10    
start  
汇报内容：读书笔记  
书籍名称：《统计学习方法》  
内容：《统计学习方法》第一章1.1-1.3  
结构：第一章主要讲述了统计学习方法的一些基本概念，首先叙述统计学习的定义、研究对象与方法；然后叙述监督学习，接着提出统计学习方法的三要素：模型、策略和算法。  
核心：统计学习三要素包括模型、策略、算法。在监督学习中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有可能的条件概率分布或决策函数。
有了模型的假设空间后，接着需要考虑按照什么样的准则学习或选择最优的模型，即统计学习的目标在于从假设空间中选择最优模型。引入损失函数和风险函数的概念，损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。常用的损失函数有以下几种：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数，损失函数值越小，模型就越好。  
算法是指学习模型的具体计算方法，统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。
总结：统计学习方法之间的不同，主要来自于其模型、策略、算法的不同。确定了模型、策略、算法，统计学习的方法也就确定了。选取最优模型时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。  
end  
####  2019.9.11  
start  
汇报内容：  
1，继续阅读学习统计学习方法1.4至1.7  
2，查找情感分析方面论文并开始阅读  
3，查找自然语言处理深度学习相关学习视频  
4，今日学习简要记录  
书籍名称：《统计学习方法》  
内容：《统计学习方法》第一章1.4-1.7  
结构：主要讲述了模型评估与模型选择，从模型评估方面讲解了训练误差与测试误差、过拟合与模型选择，从模型选择上讲解了生成模型和判别模型等。
核心：  
训练误差与测试误差：  
当损失函给定时，模型的训练误差与测试误差就称为学习方法评估的标准。训练误差是模型关于训练数据集的平均损失。测试误差是模型关于测试数据集的平均损失。测试误差小的方法具有更好的泛化能力。通常将学习方法对未知数据的预测能力成为泛化能力。  

过拟合与模型选择：  
过拟合是指学习时选择的模型所包含参数过多，以至于这一模型对一直数据预测的很好，对未知数据预测的很差。模型的选择旨在避免过拟合并提高模型的预测能力。
以多项式函数拟合问题为例，首先确定模型的复杂度，即确定多项式的次数；在给定的模型复杂度下，按照经验风险最小化的策略，求解参数，即多项式的系数。  

常用的两种模型选择方法：  
正则化和交叉验证。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则项或罚项。正则化相可以是模型参数向量的范数。  

泛化能力：  
指该方法学习到的模型对未知数据的预测能力。一般通过测试误差来评价学习方法的泛化能力。但该评价依赖与测试数据集。统计学习试图从理论上对学习方法的泛化能力进行分析提出了泛化误差，实际上，泛化误差就是学习到的模型的期望风险。  

生成模型和判别模型：  
监督学习方法又可以分为生成方法和判别方法，所学到的模型分别称为生成模型和判别模型。生成方法有数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型。模型表示了给定输入X产生输出Y的生成关系。典型的生成模型有：朴素贝叶斯法和隐马尔可夫模型。  
判别方法由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型。他关心的事对给定输入X，应该预测什么样的输出Y。典型的判别式模型：k近邻算法、感知机、决策树最大熵模型、支持向量机和条件随机场等。  

总结：训练误差和测试误差与模型复杂度之间的关系：当模型的复杂度增大时，训练误差会逐渐减小并趋向于0；测试误差会随着模型复杂度的增加先减小而后增大。在学习的时候要防止过拟合，进行最优的模型选择，以达到使测试误差最小的目的。  
end  
#### 2019.9.12
start  
书籍名称：《统计学习方法》  
内容：《统计学习方法》第一章1.8--1.10  
结构：主要讲述了三类问题：分类问题、标注问题、回归问题，他们都是监督学习的重要问题，分别介绍了他们的定义、输入输出、评价标准及应用场景。  
核心：  
监督学习从数据中学习一个分类模型或分类决策函数，称为分类器。分类器对新的输入进行输出的预测，称为分类。分类问题包括学习和分类两个过程，在学习过程中，根据已知的训练数据集利用有效的学习方法学习一个分类器P（Y|X）或Y=f（X）；在分类的过程中，利用学习的分类器对新的输入实例进行分类。对于二类分类问题常用的评价指标是精确率与召回率。分类问题可用在多种领域，譬如在文本方面的文本内容、文本特点分类。  
标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出的标记序列作为预测。学习系统基于训练数据集构建一个模型P（Y|X）或Y=f（X），标注系统按照学习得到的条件概率分布模型，对新的输入观测序列找到相应的输出标记序列。标注常用的统计学习方法有：隐马尔可夫模型、条件随机场。标注问题在信息抽取、自然语言处理等领域被广泛应用。  
回归用于预测输入变量和输出便利那个之间的关系。回归模型正是表示从输入变量到输出变量之间映射的函数。回归问题的学习等价于函数的拟合：选择一条函数使其很好的拟合已知数据且很好的预测未知数据。学习系统基于训练数据集构建一个模型Y=f(X)，预测系统根据学习的模型对新的输入确定相应的输出。回归学习最常用的损失函数式平方损失函数，在此情况下可由最小二乘法求解。  
end  
#### 2019.9.14  
start  
汇报内容：  
1，观看斯坦福自然语言处理第一课   
2，写博客整理所学知识  
3，阅读《统计学习方法》第二章   
博客内容：  
https://blog.csdn.net/qq_36812990/article/details/100799956  
end  
####  2019.9.15  
start   
汇报内容：  
1，观看斯坦福自然语言处理第二课  
2，写博客  
博客内容：https://blog.csdn.net/qq_36812990/article/details/100856697  
end  
#### 2019.9.16  
汇报人：王开心  
汇报内容：  
1.学习自然语言处理第三课  
2.更新第二节博客，在之前的基础上增加了对skip-gram模型的详解，以及参数梯度更新的推导  
3.对第三课很多概念还不太理解，明天进行查询，Glove/CBOW等模型、余弦相似度、欧氏距离、层次聚类等  
end  
#### 2019.9.17  
start  
汇报内容：  
1.学习使用python处理csv文件，读取和写入  
2.下载比赛数据集，将数据逐条使用python调用谷歌翻译成英文,再翻译成中文，并返回中文，实现回译，最终实现数据增强  
end  
#### 2019.9.19  
start   
汇报内容：  
1.学习自然语言处理课程第四节，学习笔记如图所示  
2.修改翻译代码，处理翻译字节有限制问题  
end  
#### 2019.9.20  
start  
汇报内容：  
1.读书笔记  
2.写助教培训心得  
书籍名称：《统计学习方法》  
内容：《统计学习方法》第三章  
结构：首先介绍了k近邻算法，它是一种基本的回归与分类方法。k近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的k个最近邻训练实例点，然后利用这k个训练实例点的类的多数来预测输入实例点的类。接下来具体介绍了k近邻法的三个基本要素：距离度量、k值的选择、分类决策规则。最后讲述k近邻法的一个实现方法——kd树，介绍构造和搜索kd树的算法。  
核心：k近邻法中，当训练集、距离度量、k值及分类决策规则确定后，对于任何一个 新的输入实例，它所属的类唯一地确定，这相当于根据上述要素将特征空间或氛围一些子空间，确定子空间里的每个点所属的类。  
距离度量：欧式距离、曼哈顿距离等  
k值的选择：如果选择较小的k值就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例相似的训练实例才会对预测结果起作用，但估计误差会增大；反之，如果选择较大的k值，就相当于用较大的邻域中的训练实例进行预测，优点是可以减少学习的估计误差，缺点是“学习”的近似误差会增大。在应用中，k一般选取一个较小的值，通过交叉验证选择。  
分类决策规则：k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个邻近的训练实例中的多数类决定输入实例的类。  
kd树的构造：构造根结点，使根结点对应于k维空间中包含所有实例点的超矩形区域；通过递归方法，不断对k维空间进行切分，生成子结点。在超矩形区域上选择一个坐标轴和在此坐标轴的一个切分点，将当前超矩形区域切分成左右两个子区域；实例被分到两个子区域，直到子区域内没有实例时终止，将实例保存在相应的结点上。（通常选择训练实例点在选定坐标轴的中位数为切分点。）  
kd树的搜索：给定一个目标标点，搜索其最近邻，首先找到包含目标点的叶结点，然后从该叶结点出发，一次退回到父结点，不断查找与目标点最邻近的结点（判断超矩形区域是否与超球体相交），当确定不可能存在更近的结点时终止。  
总结：kd树是二叉树，表示对k维空间的一个划分，其每个节点对应于k维空间划分中的一个超矩形区域。可以省去对大部分数据点的搜索，减少搜索的计算量。  
end  
####  2019.9.21
start   
汇报内容：  
1.读书笔记  
2.修改回译代码，处理单行文本超过4800字节的文本。  
书籍名称：《统计学习方法》  
内容：《统计学习方法》第四章  
结构：第四章主要讲述了朴素贝叶斯法，包括朴素贝叶斯法的学习与分类、朴素贝叶斯法的参数估计法（极大似然估计和贝叶斯估计）。  
核心：朴素贝叶斯是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。  
总结：  
1.朴素贝叶斯法是典型的生成学习方法。生成学习由训练数据学习联合概率分布P(X，Y)，然后求得后验概率分布P(Y|X)。具体来说，利用训练数据学习P(X|Y)和P(Y)的估计，得到联合概率分布：  
P(X,Y)=P(Y)P(X|Y)  
2.我们根据推导得出，根据期望风险最小化准则得到后验概率最大化准则。  
####  2019.9.24  
start  
汇报内容：  
1.整理老师课上所讲算法  
2.购买阿里云服务器，并部署。将过程记录在博客上：https://blog.csdn.net/qq_36812990/article/details/101307224  
end   
#### 2019.9.25  
start   
汇报内容：  
1.整理对比Word2vec、ELMO、BERT模型，并整理制作PPT  
2.开始阅读《Attention Is All You Need》论文，主要讲述Transformer模型。BERT主要基于这一模型  
end  



